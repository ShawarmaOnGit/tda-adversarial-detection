{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2eacbb",
   "metadata": {},
   "source": [
    "# 02 - Feature Extraction\n",
    "\n",
    "**Goal:** Extract high-level feature representations from CIFAR-10 using pretrained ResNet50\n",
    "\n",
    "## Overview\n",
    "In this notebook, we will:\n",
    "1. Load the full CIFAR-10 dataset\n",
    "2. Extract 2048-dimensional features using ResNet50\n",
    "3. Apply PCA to reduce dimensionality to 50D\n",
    "4. Visualize the reduced feature space\n",
    "5. Save features for TDA analysis\n",
    "\n",
    "**Why Feature Extraction?**\n",
    "- Raw pixels (32×32×3 = 3,072 dims) are noisy and high-dimensional\n",
    "- ResNet50 learns semantic features (objects, textures, shapes)\n",
    "- These features are better suited for TDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa80476",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f209ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Our modules\n",
    "from src.data.cifar10 import load_cifar10\n",
    "from src.models.feature_extractor import FeatureExtractor, DimensionalityReducer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568f22b",
   "metadata": {},
   "source": [
    "### Load the CIFAR-10 Dataset\n",
    "\n",
    "We'll use a subset of 5,000 training samples for faster experimentation. For the final paper, we'll scale up to the full 45,000 training samples.\n",
    "\n",
    "You can test with any number of training samples you like by changing the `5000` to a different number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac47f050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final splits:\n",
      "Training:   45000 samples\n",
      "Validation: 5000 samples\n",
      "Testing:    10000 samples\n",
      "\n",
      "Using 5,000 training samples for feature extraction\n"
     ]
    }
   ],
   "source": [
    "(training_images, training_labels), (validation_images, validation_labels), (testing_images, testing_labels), class_names = load_cifar10()\n",
    "\n",
    "training_images_subset = training_images[:5000]   # 5000 images for quick experiment\n",
    "training_labels_subset = training_labels[:5000]   # 5000 labels for quick experiment\n",
    "\n",
    "print(f\"\\nUsing {len(training_images_subset):,} training samples for feature extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0506c2f",
   "metadata": {},
   "source": [
    "### Initialize Feature Extractor\n",
    "\n",
    "We'll use **ResNet50** pretrained on ImageNet:\n",
    "- **2048-dimensional** feature vectors\n",
    "- Captures high-level semantic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f38665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 22:21:52.767352: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-11-29 22:21:52.768495: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-11-29 22:21:52.768501: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-11-29 22:21:52.769152: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-29 22:21:52.769987: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: resnet50\n",
      "Feature dimension: 2048\n",
      "Total parameters: 23,587,712\n"
     ]
    }
   ],
   "source": [
    "extractor = FeatureExtractor(model_name='resnet50')   # Initialize the extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56814d25",
   "metadata": {},
   "source": [
    "### Extract Features from Training Set\n",
    "\n",
    "This step processes each image through ResNet50 to extract feature vectors.  \n",
    "**Expected time:** ~2-3 minutes for 5,000 images on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20aa11c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature extraction in progress... :   0%|          | 0/79 [00:00<?, ?batch/s]\n",
      "Feature extraction in progress... :   1%|▏         | 1/79 [00:01<02:14,  1.73s/batch]\n",
      "Feature extraction in progress... :   3%|▎         | 2/79 [00:03<02:20,  1.83s/batch]\n",
      "Feature extraction in progress... :   4%|▍         | 3/79 [00:05<02:07,  1.68s/batch]\n",
      "Feature extraction in progress... :   5%|▌         | 4/79 [00:07<02:29,  1.99s/batch]\n",
      "Feature extraction in progress... :   6%|▋         | 5/79 [00:09<02:25,  1.97s/batch]\n",
      "Feature extraction in progress... :   8%|▊         | 6/79 [00:10<02:05,  1.71s/batch]\n",
      "Feature extraction in progress... :   9%|▉         | 7/79 [00:12<02:03,  1.72s/batch]\n",
      "Feature extraction in progress... :  10%|█         | 8/79 [00:14<02:00,  1.70s/batch]\n",
      "Feature extraction in progress... :  11%|█▏        | 9/79 [00:17<02:27,  2.11s/batch]\n",
      "Feature extraction in progress... :  13%|█▎        | 10/79 [00:18<02:07,  1.85s/batch]\n",
      "Feature extraction in progress... :  14%|█▍        | 11/79 [00:19<01:52,  1.66s/batch]\n",
      "Feature extraction in progress... :  15%|█▌        | 12/79 [00:21<01:46,  1.58s/batch]\n",
      "Feature extraction in progress... :  16%|█▋        | 13/79 [00:22<01:46,  1.61s/batch]\n",
      "Feature extraction in progress... :  18%|█▊        | 14/79 [00:24<01:41,  1.55s/batch]\n",
      "Feature extraction in progress... :  19%|█▉        | 15/79 [00:26<01:58,  1.85s/batch]\n",
      "Feature extraction in progress... :  20%|██        | 16/79 [00:28<01:53,  1.80s/batch]\n",
      "Feature extraction in progress... :  22%|██▏       | 17/79 [00:29<01:40,  1.62s/batch]\n",
      "Feature extraction in progress... :  23%|██▎       | 18/79 [00:30<01:32,  1.51s/batch]\n",
      "Feature extraction in progress... :  24%|██▍       | 19/79 [00:32<01:27,  1.46s/batch]\n",
      "Feature extraction in progress... :  25%|██▌       | 20/79 [00:33<01:26,  1.46s/batch]\n",
      "Feature extraction in progress... :  27%|██▋       | 21/79 [00:35<01:30,  1.56s/batch]\n",
      "Feature extraction in progress... :  28%|██▊       | 22/79 [00:36<01:25,  1.50s/batch]\n",
      "Feature extraction in progress... :  29%|██▉       | 23/79 [00:38<01:24,  1.50s/batch]\n",
      "Feature extraction in progress... :  30%|███       | 24/79 [00:39<01:21,  1.48s/batch]\n",
      "Feature extraction in progress... :  32%|███▏      | 25/79 [00:41<01:32,  1.71s/batch]\n",
      "Feature extraction in progress... :  33%|███▎      | 26/79 [00:43<01:34,  1.79s/batch]\n",
      "Feature extraction in progress... :  34%|███▍      | 27/79 [00:45<01:26,  1.67s/batch]\n",
      "Feature extraction in progress... :  35%|███▌      | 28/79 [00:47<01:27,  1.71s/batch]\n",
      "Feature extraction in progress... :  37%|███▋      | 29/79 [00:48<01:21,  1.63s/batch]\n",
      "Feature extraction in progress... :  38%|███▊      | 30/79 [00:49<01:15,  1.55s/batch]\n",
      "Feature extraction in progress... :  39%|███▉      | 31/79 [00:51<01:17,  1.62s/batch]\n",
      "Feature extraction in progress... :  41%|████      | 32/79 [00:56<01:56,  2.47s/batch]\n",
      "Feature extraction in progress... :  42%|████▏     | 33/79 [00:57<01:38,  2.15s/batch]\n",
      "Feature extraction in progress... :  43%|████▎     | 34/79 [00:58<01:26,  1.93s/batch]\n",
      "Feature extraction in progress... :  44%|████▍     | 35/79 [01:00<01:15,  1.71s/batch]\n",
      "Feature extraction in progress... :  46%|████▌     | 36/79 [01:01<01:05,  1.53s/batch]\n",
      "Feature extraction in progress... :  47%|████▋     | 37/79 [01:02<01:04,  1.52s/batch]\n",
      "Feature extraction in progress... :  48%|████▊     | 38/79 [01:04<00:59,  1.46s/batch]\n",
      "Feature extraction in progress... :  49%|████▉     | 39/79 [01:05<00:55,  1.38s/batch]\n",
      "Feature extraction in progress... :  51%|█████     | 40/79 [01:06<00:55,  1.43s/batch]\n",
      "Feature extraction in progress... :  52%|█████▏    | 41/79 [01:08<00:55,  1.46s/batch]\n",
      "Feature extraction in progress... :  53%|█████▎    | 42/79 [01:09<00:55,  1.50s/batch]\n",
      "Feature extraction in progress... :  54%|█████▍    | 43/79 [01:11<00:56,  1.56s/batch]\n",
      "Feature extraction in progress... :  56%|█████▌    | 44/79 [01:13<00:55,  1.58s/batch]\n",
      "Feature extraction in progress... :  57%|█████▋    | 45/79 [01:14<00:51,  1.52s/batch]\n",
      "Feature extraction in progress... :  58%|█████▊    | 46/79 [01:16<00:53,  1.62s/batch]\n",
      "Feature extraction in progress... :  59%|█████▉    | 47/79 [01:18<00:52,  1.64s/batch]\n",
      "Feature extraction in progress... :  61%|██████    | 48/79 [01:19<00:48,  1.58s/batch]\n",
      "Feature extraction in progress... :  62%|██████▏   | 49/79 [01:20<00:44,  1.47s/batch]\n",
      "Feature extraction in progress... :  63%|██████▎   | 50/79 [01:22<00:40,  1.39s/batch]\n",
      "Feature extraction in progress... :  65%|██████▍   | 51/79 [01:23<00:37,  1.34s/batch]\n",
      "Feature extraction in progress... :  66%|██████▌   | 52/79 [01:24<00:35,  1.30s/batch]\n",
      "Feature extraction in progress... :  67%|██████▋   | 53/79 [01:25<00:33,  1.28s/batch]\n",
      "Feature extraction in progress... :  68%|██████▊   | 54/79 [01:27<00:33,  1.34s/batch]\n",
      "Feature extraction in progress... :  70%|██████▉   | 55/79 [01:28<00:32,  1.34s/batch]\n",
      "Feature extraction in progress... :  71%|███████   | 56/79 [01:29<00:30,  1.34s/batch]\n",
      "Feature extraction in progress... :  72%|███████▏  | 57/79 [01:31<00:31,  1.45s/batch]\n",
      "Feature extraction in progress... :  73%|███████▎  | 58/79 [01:33<00:31,  1.48s/batch]\n",
      "Feature extraction in progress... :  75%|███████▍  | 59/79 [01:34<00:28,  1.42s/batch]\n",
      "Feature extraction in progress... :  76%|███████▌  | 60/79 [01:35<00:27,  1.45s/batch]\n",
      "Feature extraction in progress... :  77%|███████▋  | 61/79 [01:37<00:25,  1.44s/batch]\n",
      "Feature extraction in progress... :  78%|███████▊  | 62/79 [01:38<00:24,  1.43s/batch]\n",
      "Feature extraction in progress... :  80%|███████▉  | 63/79 [01:40<00:24,  1.53s/batch]\n",
      "Feature extraction in progress... :  81%|████████  | 64/79 [01:42<00:22,  1.53s/batch]\n",
      "Feature extraction in progress... :  82%|████████▏ | 65/79 [01:43<00:21,  1.53s/batch]\n",
      "Feature extraction in progress... :  84%|████████▎ | 66/79 [01:45<00:20,  1.60s/batch]\n",
      "Feature extraction in progress... :  85%|████████▍ | 67/79 [01:47<00:20,  1.67s/batch]\n",
      "Feature extraction in progress... :  86%|████████▌ | 68/79 [01:48<00:17,  1.64s/batch]\n",
      "Feature extraction in progress... :  87%|████████▋ | 69/79 [01:50<00:17,  1.73s/batch]\n",
      "Feature extraction in progress... :  89%|████████▊ | 70/79 [01:52<00:15,  1.68s/batch]\n",
      "Feature extraction in progress... :  90%|████████▉ | 71/79 [01:53<00:12,  1.62s/batch]\n",
      "Feature extraction in progress... :  91%|█████████ | 72/79 [01:54<00:10,  1.48s/batch]\n",
      "Feature extraction in progress... :  92%|█████████▏| 73/79 [01:56<00:08,  1.38s/batch]\n",
      "Feature extraction in progress... :  94%|█████████▎| 74/79 [01:57<00:06,  1.33s/batch]\n",
      "Feature extraction in progress... :  95%|█████████▍| 75/79 [01:58<00:05,  1.28s/batch]\n",
      "Feature extraction in progress... :  96%|█████████▌| 76/79 [01:59<00:03,  1.23s/batch]\n",
      "Feature extraction in progress... :  97%|█████████▋| 77/79 [02:00<00:02,  1.20s/batch]\n",
      "Feature extraction in progress... :  99%|█████████▊| 78/79 [02:01<00:01,  1.18s/batch]\n",
      "Feature extraction in progress... : 100%|██████████| 79/79 [02:02<00:00,  1.02batch/s]\n",
      "Feature extraction in progress... : 100%|██████████| 79/79 [02:02<00:00,  1.55s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted features from 5,000 images\n",
      "Feature shape: (5000, 2048)\n",
      "Feature range: [0.000, 17.504]\n",
      "\n",
      "Feature extraction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_features = extractor.extract_features(\n",
    "    training_images_subset, \n",
    "    batch_size=64,\n",
    "    resize_to=224,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFeature extraction complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29cf53",
   "metadata": {},
   "source": [
    "### Feature Statistics\n",
    "\n",
    "Let's analyze the extracted features before dimensionality reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d01e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5000, 2048)\n",
      "5,000 samples x 2,048 dimensions\n",
      "\n",
      "Value Range:\n",
      "Min:    0.0000\n",
      "Max:    17.5043\n",
      "Mean:   0.0910\n",
      "Std:    0.6063\n",
      "\n",
      "Sparsity:\n",
      "78.00% of feature values are exactly zero\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {clean_features.shape}\")\n",
    "print(f\"{clean_features.shape[0]:,} samples x {clean_features.shape[1]:,} dimensions\")\n",
    "\n",
    "print(f\"\\nValue Range:\")\n",
    "print(f\"Min:    {clean_features.min():.4f}\")\n",
    "print(f\"Max:    {clean_features.max():.4f}\")\n",
    "print(f\"Mean:   {clean_features.mean():.4f}\")\n",
    "print(f\"Std:    {clean_features.std():.4f}\")\n",
    "\n",
    "print(f\"\\nSparsity:\")\n",
    "zero_ratio = (clean_features == 0).sum() / clean_features.size\n",
    "print(f\"{zero_ratio:.2%} of feature values are exactly zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bca2ca",
   "metadata": {},
   "source": [
    "These numbers have no natural units; they represent activation strength. We can think of each number like a score:\n",
    "- 0 → this feature wasn’t present\n",
    "- 17.5043 → this feature appeared strongly\n",
    "- 0.09 mean → most features are weakly activated on average\n",
    "- std 0.606 → most values cluster < 1, a few rare spikes go higher\n",
    "\n",
    "Each feature is a completely different concept, so its scale doesn’t matter relative to another feature. What actually matters is:\n",
    "- Patterns across **ALL** 2048 numbers\n",
    "- Which features activate together\n",
    "- How feature vectors cluster in space\n",
    "\n",
    "That’s why **PCA** is useful since it captures the geometry of these activation patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c9236",
   "metadata": {},
   "source": [
    "### Apply PCA Dimensionality Reduction\n",
    "\n",
    "**Why reduce dimensions?**\n",
    "- 2048 dimensions is computationally expensive for TDA\n",
    "- However, 50 dimensions is fast while also preserving approximately 95% of variance\n",
    "- Removes noise and redundant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0771ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying PCA...\n",
      "Original feature dimension: 2048\n",
      "Target dimension: 50\n",
      "\n",
      "PCA dimensionality reduction complete\n",
      "Original: (5000, 2048)\n",
      "Reduced:  (5000, 50)\n"
     ]
    }
   ],
   "source": [
    "reducer = DimensionalityReducer(n_components=50, random_state=111)             # PCA reducer\n",
    "clean_features_reduced = reducer.fit_transform(clean_features, verbose=True)   # Fit and transform features\n",
    "\n",
    "print(f\"\\nPCA dimensionality reduction complete\")\n",
    "print(f\"Original: {clean_features.shape}\")\n",
    "print(f\"Reduced:  {clean_features_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156c8fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0185fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7f10315",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa3a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
