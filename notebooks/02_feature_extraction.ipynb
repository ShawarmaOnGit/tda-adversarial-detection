{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2eacbb",
   "metadata": {},
   "source": [
    "# 02 - Feature Extraction\n",
    "\n",
    "**Goal:** Extract high-level feature representations from CIFAR-10 using pretrained ResNet50\n",
    "\n",
    "## Overview\n",
    "In this notebook, we will:\n",
    "1. Load the full CIFAR-10 dataset\n",
    "2. Extract 2048-dimensional features using ResNet50\n",
    "3. Apply PCA to reduce dimensionality to 50D\n",
    "4. Visualize the reduced feature space\n",
    "5. Save features for TDA analysis\n",
    "\n",
    "**Why Feature Extraction?**\n",
    "- Raw pixels (32×32×3 = 3,072 dims) are noisy and high-dimensional\n",
    "- ResNet50 learns semantic features (objects, textures, shapes)\n",
    "- These features are better suited for TDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa80476",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f209ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Our modules\n",
    "from src.data.cifar10 import load_cifar10\n",
    "from src.models.feature_extractor import FeatureExtractor, DimensionalityReducer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568f22b",
   "metadata": {},
   "source": [
    "### Load the CIFAR-10 Dataset\n",
    "\n",
    "We'll use a subset of 5,000 training samples for faster experimentation. For the final paper, we'll scale up to the full 45,000 training samples.\n",
    "\n",
    "You can test with any number of training samples you like by changing the `5000` to a different number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac47f050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final splits:\n",
      "Training:   45000 samples\n",
      "Validation: 5000 samples\n",
      "Testing:    10000 samples\n",
      "\n",
      "Using 5,000 training samples for feature extraction\n"
     ]
    }
   ],
   "source": [
    "(training_images, training_labels), (validation_images, validation_labels), (testing_images, testing_labels), class_names = load_cifar10()\n",
    "\n",
    "training_images_subset = training_images[:5000]   # 5000 images for quick experiment\n",
    "training_labels_subset = training_labels[:5000]   # 5000 labels for quick experiment\n",
    "\n",
    "print(f\"\\nUsing {len(training_images_subset):,} training samples for feature extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0506c2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38665e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56814d25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa11c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e29cf53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d01e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
